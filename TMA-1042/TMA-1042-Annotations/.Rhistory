contributors()
demo()
# provide path where coordinates files are located
path = ''
sessionInfo()
# provide path where coordinates files are located
path = '/Users/mihaoyang/Desktop/output'
source('/Users/mihaoyang/Desktop/DigitalPathologyFunctions.R')
install.packages('spatstat')
install.packages('largeVis')
install.packages("~/Desktop/largeVis_0.1.9.1.tar.gz", repos = NULL, type = "source")
install.packages('stats')
install.packages("stats")
install.packages("stats")
install.packages("stats")
install.packages("alphaull")
install.packages("alphanull")
install.packages("~/Desktop/alphahull_2.0.tar.gz", repos = NULL, type = "source")
# provide path where coordinates files are located
path = '/Users/mihaoyang/Desktop/output'
source('/Users/mihaoyang/Desktop/DigitalPathologyFunctions.R')
install.packages('spatstat')
# provide path where coordinates files are located
path = '/Users/mihaoyang/Desktop/output'
source('/Users/mihaoyang/Desktop/DigitalPathologyFunctions.R')
p_th = 5E-2
ids = list.dirs(path=path,recursive=FALSE, full.names = FALSE)
count = p_all <- matrix(nrow=length(ids),ncol=1)
for (slideId in ids){
slidepath = paste(path, slideId, "\\",  sep="")
filename = paste(slideId,"_allPoints.csv", sep="")
outname = "fittedResult_scan.5.csv"
processSlide(slidepath,filename,outname, alpha = p_th, window=.5,step=.25)
}
segSuffix = "_allPoints.csv"
# provide path to save clustering output
clusterOutPath = ''
for(slideId in ids){
file = paste(path, slideId, "\\", slideId, segSuffix, sep="")
dir.create(paste(clusterOutPath, slideId, sep=""))
outfile = paste(clusterOutPath, slideId, "\\", slideId, "_shape.csv", sep="")
outfileOutline = paste(clusterOutPath, slideId, "\\", slideId, "_shape_outline.csv", sep="")
if (file.exists(file)){
allPoints <- read.csv(file, row.names = 1)
}else{
print(file)
print('file not exist')
next
}
subPoints <- allPoints
# clustering
minPts = 30
K = 4
dat <- as.matrix(subPoints[, 1:2])
cd8vis <- largeVis(t(dat), dim=2, K = K, tree_threshold = 100, max_iter = 5,
sgd_batches = 1, threads = 1)
clusters <- hdbscan(cd8vis, K=K, minPts = minPts, verbose = FALSE, threads = 1)
#fig = gplot(clusters, dat)
#show(fig)
# for each cluster
hullStats <- matrix(nrow = 0, ncol = 4) # n, perimeter, area, convexity
ellStats <- matrix(nrow = 0, ncol = 4) # x, y, major, minor
centStats <- matrix(nrow = 0, ncol = 3) # xc, yc, moment of inertia
regionStats<- matrix(nrow = 0, ncol = 3) # number in tumor, stroma, front
polygonInfo <- matrix(nrow = 0, ncol = 3) #clusterID, x, y
alpha0 <- 0.01
alphaStep <- 0.01
maxCluster = max(as.numeric(clusters$clusters), na.rm = TRUE)
minCluster = min(as.numeric(clusters$clusters), na.rm = TRUE)
notNA = !is.na(clusters$clusters)
for(cid_target in 1:maxCluster) {
cidMatch <- notNA & clusters$clusters == cid_target
goodAlpha = FALSE
alpha <- alpha0
#X<-subPoints[cidMatch,]
X<-subPoints[cidMatch,1:2]
# try different alpha until shape covers all points
while(!goodAlpha){
alpha <- alpha + alphaStep
ashapeX <- ashape(X, alpha = alpha)
#plot(ashapeX, xlab = "x", ylab = "y")
res=getAlphaShapeInOrder(ashapeX)
goodAlpha <- res@goodAshape
}
nPt <-nrow(X)
### get alpha-perimeter
Pconc <- ashapeX$length
### get alpha-area:
alphaShape <- Polygon(X[res@vert,])
Aconc <- alphaShape@area
### polygon outline
polygonInfo = rbind(polygonInfo,
cbind(rep(cid_target, length(alphaShape@coords[,1])),
alphaShape@coords))
### get convex hull
hullPts <- chull(X)
hullPts <- c(hullPts, hullPts[1])
# lines(X[hpts, ])
convShape <- Polygon(X[hullPts, ])
## plot the polygon of convex hull
#polygon(X[hullPts, 1], X[hullPts,2], col = "gray", border = "red")
### convex hull area
Aconv<-convShape@area
hullStats = rbind(hullStats, as.matrix(t(c(nPt, Pconc, Aconc, Aconv))))
## fitting ellipse
# we can get center and covariance matrix from the cluster points:
ellFit <- cov.wt(X)
# eigen vectors indicate orientations
ellEigen <- eigen(ellFit$cov)
# eigen values are associated with major/minor axes length (half)
#axes <- sqrt(ellEigen$values * 2 * qf(.95, 2, length(t(X))-1))
# alternative: chi square distribution
axes <- sqrt(ellEigen$values * qchisq(.95, df=2))
ellStats = rbind(ellStats, as.matrix(t(c(ellFit$center[1],ellFit$center[2],
axes[1], axes[2]))))
#centroid and moment of inersia
centStats = rbind(centStats, as.matrix(t(c(colMeans(X), sum(sweep(X,2,colMeans(X))^2)))))
regionStats = rbind(regionStats, colSums(subPoints[cidMatch,], dims=1)[3:5])
}
hullStats=data.frame(hullStats)
colnames(hullStats)<-c("n", "perimConcave","areaConcave","areaConvex")
shapeStats = hullStats
shapeStats$n_tumor = regionStats[,1]
shapeStats$n_stroma = regionStats[,2]
shapeStats$n_front = regionStats[,3]
shapeStats$circ = shapeStats$areaConcave*4*pi/(shapeStats$perimConcave)^2
shapeStats$conv = shapeStats$areaConcave/shapeStats$areaConvex
shapeStats$density = shapeStats$n/shapeStats$areaConcave
shapeStats$x = ellStats[,1]
shapeStats$y = ellStats[,2]
shapeStats$major = ellStats[,3]
shapeStats$minor = ellStats[,4]
shapeStats$eccentricity = sqrt(1-(shapeStats$minor/shapeStats$major)^2)
shapeStats$xc = centStats[,1]
shapeStats$yc = centStats[,2]
shapeStats$moi = centStats[,3]
polygonDF = data.frame(polygonInfo)
colnames(polygonDF)<-c("cluster_ID", "x","y")
write.csv(shapeStats, file = outfile)
write.csv(polygonDF, file = outfileOutline, row.names=FALSE)
}
source('/Users/mihaoyang/Desktop/DigitalPathologyFunctions.R')
processSlide(slidepath,filename,outname, alpha = p_th, window=.5,step=.25)
for (slideId in ids){
slidepath = paste(path, slideId, "\\",  sep="")
filename = paste(slideId,"_allPoints.csv", sep="")
outname = "fittedResult_scan.5.csv"
source('/Users/mihaoyang/Desktop/DigitalPathologyFunctions.R')
processSlide(slidepath,filename,outname, alpha = p_th, window=.5,step=.25)
}
segSuffix = "_allPoints.csv"
# provide path to save clustering output
clusterOutPath = ''
for(slideId in ids){
file = paste(path, slideId, "\\", slideId, segSuffix, sep="")
dir.create(paste(clusterOutPath, slideId, sep=""))
outfile = paste(clusterOutPath, slideId, "\\", slideId, "_shape.csv", sep="")
outfileOutline = paste(clusterOutPath, slideId, "\\", slideId, "_shape_outline.csv", sep="")
if (file.exists(file)){
allPoints <- read.csv(file, row.names = 1)
}else{
print(file)
print('file not exist')
next
}
subPoints <- allPoints
# clustering
minPts = 30
K = 4
dat <- as.matrix(subPoints[, 1:2])
cd8vis <- largeVis(t(dat), dim=2, K = K, tree_threshold = 100, max_iter = 5,
sgd_batches = 1, threads = 1)
clusters <- hdbscan(cd8vis, K=K, minPts = minPts, verbose = FALSE, threads = 1)
#fig = gplot(clusters, dat)
#show(fig)
# for each cluster
hullStats <- matrix(nrow = 0, ncol = 4) # n, perimeter, area, convexity
ellStats <- matrix(nrow = 0, ncol = 4) # x, y, major, minor
centStats <- matrix(nrow = 0, ncol = 3) # xc, yc, moment of inertia
regionStats<- matrix(nrow = 0, ncol = 3) # number in tumor, stroma, front
polygonInfo <- matrix(nrow = 0, ncol = 3) #clusterID, x, y
alpha0 <- 0.01
alphaStep <- 0.01
maxCluster = max(as.numeric(clusters$clusters), na.rm = TRUE)
minCluster = min(as.numeric(clusters$clusters), na.rm = TRUE)
notNA = !is.na(clusters$clusters)
for(cid_target in 1:maxCluster) {
cidMatch <- notNA & clusters$clusters == cid_target
goodAlpha = FALSE
alpha <- alpha0
#X<-subPoints[cidMatch,]
X<-subPoints[cidMatch,1:2]
# try different alpha until shape covers all points
while(!goodAlpha){
alpha <- alpha + alphaStep
ashapeX <- ashape(X, alpha = alpha)
#plot(ashapeX, xlab = "x", ylab = "y")
res=getAlphaShapeInOrder(ashapeX)
goodAlpha <- res@goodAshape
}
nPt <-nrow(X)
### get alpha-perimeter
Pconc <- ashapeX$length
### get alpha-area:
alphaShape <- Polygon(X[res@vert,])
Aconc <- alphaShape@area
### polygon outline
polygonInfo = rbind(polygonInfo,
cbind(rep(cid_target, length(alphaShape@coords[,1])),
alphaShape@coords))
### get convex hull
hullPts <- chull(X)
hullPts <- c(hullPts, hullPts[1])
# lines(X[hpts, ])
convShape <- Polygon(X[hullPts, ])
## plot the polygon of convex hull
#polygon(X[hullPts, 1], X[hullPts,2], col = "gray", border = "red")
### convex hull area
Aconv<-convShape@area
hullStats = rbind(hullStats, as.matrix(t(c(nPt, Pconc, Aconc, Aconv))))
## fitting ellipse
# we can get center and covariance matrix from the cluster points:
ellFit <- cov.wt(X)
# eigen vectors indicate orientations
ellEigen <- eigen(ellFit$cov)
# eigen values are associated with major/minor axes length (half)
#axes <- sqrt(ellEigen$values * 2 * qf(.95, 2, length(t(X))-1))
# alternative: chi square distribution
axes <- sqrt(ellEigen$values * qchisq(.95, df=2))
ellStats = rbind(ellStats, as.matrix(t(c(ellFit$center[1],ellFit$center[2],
axes[1], axes[2]))))
#centroid and moment of inersia
centStats = rbind(centStats, as.matrix(t(c(colMeans(X), sum(sweep(X,2,colMeans(X))^2)))))
regionStats = rbind(regionStats, colSums(subPoints[cidMatch,], dims=1)[3:5])
}
hullStats=data.frame(hullStats)
colnames(hullStats)<-c("n", "perimConcave","areaConcave","areaConvex")
shapeStats = hullStats
shapeStats$n_tumor = regionStats[,1]
shapeStats$n_stroma = regionStats[,2]
shapeStats$n_front = regionStats[,3]
shapeStats$circ = shapeStats$areaConcave*4*pi/(shapeStats$perimConcave)^2
shapeStats$conv = shapeStats$areaConcave/shapeStats$areaConvex
shapeStats$density = shapeStats$n/shapeStats$areaConcave
shapeStats$x = ellStats[,1]
shapeStats$y = ellStats[,2]
shapeStats$major = ellStats[,3]
shapeStats$minor = ellStats[,4]
shapeStats$eccentricity = sqrt(1-(shapeStats$minor/shapeStats$major)^2)
shapeStats$xc = centStats[,1]
shapeStats$yc = centStats[,2]
shapeStats$moi = centStats[,3]
polygonDF = data.frame(polygonInfo)
colnames(polygonDF)<-c("cluster_ID", "x","y")
write.csv(shapeStats, file = outfile)
write.csv(polygonDF, file = outfileOutline, row.names=FALSE)
}
install.packages('spatstat')
# provide path where coordinates files are located
path = '/Users/mihaoyang/Desktop/output'
source('/Users/mihaoyang/Desktop/D
gitalPathologyFunctions.R')
source('/Users/mihaoyang/Desktop/DgitalPathologyFunctions.R')
source('/Users/mihaoyang/Desktop/DigitalPathologyFunctions.R')
install.packages("~/Desktop/largeVis_0.1.9.1.tar.gz", repos = NULL, type = "source")
install.packages("~/Desktop/largeVis_0.2.1.1.tar.gz", repos = NULL, type = "source")
install.packages("ggplot2")
install.packages('spatstat')
source('/Users/mihaoyang/Desktop/DigitalPathologyFunctions.R')
install.packages("~/Desktop/largeVis_0.2.1.1.tar.gz", repos = NULL, type = "source")
install.packages("RcppProgress")
install.packages("RcppArmadillo")
install.packages("~/Desktop/largeVis_0.2.1.1.tar.gz", repos = NULL, type = "source")
install.packages("testthat")
install.packages("~/Desktop/largeVis_0.2.1.1.tar.gz", repos = NULL, type = "source")
install.packages("RcppArmadillo")
install.packages("~/Desktop/largeVis_0.2.1.1.tar.gz", repos = NULL, type = "source")
source('/Users/mihaoyang/Desktop/DigitalPathologyFunctions.R')
p_th = 5E-2
ids = list.dirs(path=path,recursive=FALSE, full.names = FALSE)
# provide path where coordinates files are located
path = '/Users/mihaoyang/Desktop/output'
source('/Users/mihaoyang/Desktop/DigitalPathologyFunctions.R')
install.packages("dbscan")
# provide path where coordinates files are located
path = '/Users/mihaoyang/Desktop/output'
source('/Users/mihaoyang/Desktop/DigitalPathologyFunctions.R')
source('/Users/mihaoyang/Desktop/DigitalPathologyFunctions.R')
source('~/Desktop/DigitalPathologyFunctions.R')
source('~/Desktop/fcbb2_homework_2.R')
install.packages(kernlab)
install.packages('kernlab')
source('~/Desktop/fcbb2_homework_2.R')
source('~/Desktop/fcbb2_homework_2.R')
install.packages('kernlab')
###########################################
## This script is to select valid cores ###
###########################################
library(dplyr)
library(stats)
library(reshape2)
library(gridExtra)
library(cowplot) # 1.0.0
library(scales)
library(stringr)
#pca
library(ggfortify)
library(ggbiplot)
# t-SNE
library(Rtsne)
library(largeVis)
library(cluster)
set.seed(1)
# set directory
setwd("~/Desktop/TMA-1042-Annotations")
# step 1: read csv file
allStats <- read.csv('allTMA_tissueArea.csv')
# step 2: split the image name for matching
allStats$Image <- str_split_fixed(allStats$Image, "_", 6)[,4]
#-------------- t-SNE dat -----------------#
t_SNE_dat <- matrix(nrow = 0, ncol = 2)
colnames(t_SNE_dat) <- c('stain_name', 'V2')
new_stain_dat <- matrix(nrow = 0, ncol = 2)
for(flag in 1:10){ # num of stainings
# list of stain vectors
stain_name <- switch (flag, 'HE', 'P16', 'P53', 'P63', 'uv-GATA3', 'Ki67', 'CK20', 'CK5-6', 'Her2Neu', 'Cyclin')
stain_dat <- allStats[allStats$Image == stain_name,]
new_stain_dat <- matrix(nrow = 0, ncol = 2)
for(letter in LETTERS[1:12]){
for(num in 1:13){
# core name
coreName <- paste(letter, '-', num, sep = '')
# get the core dat for curremt stain
stain_core_dat <- stain_dat[stain_dat$TMA.core == coreName,]
if(nrow(stain_core_dat) != 0){
coreArea <- sum(stain_core_dat$Area.µm.2)*0.454*0.454/10^6
sum_dat <- cbind(coreName, coreArea)
colnames(sum_dat) <- c('TMA.core', 'Area')
new_stain_dat <- data.frame(rbind(new_stain_dat, sum_dat))
# remove the core dat from original df
#stain_dat <- anti_join(stain_dat, stain_core_dat)
}
colnames(new_stain_dat) <- c('TMA.core', 'Area')
new_stain_dat <- unique(new_stain_dat)
}
}
if(stain_name == 'HE'){
Merge_stats <- new_stain_dat
} else {
Merge_stats <- merge(Merge_stats, new_stain_dat, by = 'TMA.core')
}
# prepare t-SNE data
t_SNE_dat <- data.frame(rbind(t_SNE_dat, cbind(stain_name, as.numeric(as.character(new_stain_dat$Area)))))
}
Merge_stats[,2:11] <- as.matrix(Merge_stats[,2:11])
CV <- data.frame(matrix(nrow = 0, ncol = 1))
Mean <- data.frame(matrix(nrow = 0, ncol = 1))
QCoD <- data.frame(matrix(nrow = 0, ncol = 1))
for(i in 1:nrow(Merge_stats)){ # num of stainings
vec <- as.numeric(as.character(Merge_stats[i, 2:11]))
CV <- rbind(CV, sd(vec)/mean(vec))
Mean <- rbind(Mean, mean(vec))
QCoD <-  rbind(QCoD, (quantile(vec, 0.75) - quantile(vec, 0.25))/(quantile(vec, 0.75) + quantile(vec, 0.25)))
}
Merge_stats <- data.frame(cbind(Merge_stats, Mean, CV, QCoD))
colnames(Merge_stats) <- c('TMA.core', 'H&E', 'P16', 'P53', 'P63', 'uv-GATA3', 'Ki67', 'CK20', 'CK5-6', 'Her2Neu', 'Cyclin', 'Mean', 'CoV', 'QCoD')
Merge_stats$TMA.core <- as.factor(Merge_stats$TMA.core)
Merge_stats <- Merge_stats[order(Merge_stats$Mean),]
Merge_stas_mean_order <- Merge_stats[,c(1, 12:14)]
# sort the dataframe for boxplot
Merge_stats_melt <- melt(data = Merge_stats[, c(1:11)], id.vars = 'TMA.core', measure.vars =  c('H&E', 'P16', 'P53', 'P63', 'uv-GATA3', 'Ki67', 'CK20', 'CK5-6', 'Her2Neu', 'Cyclin'))
Merge_stats_melt$value <- as.numeric(Merge_stats_melt$value)
tsne_df = setNames(data.frame(t(Merge_stats[,-c(1,12,13,14)])), Merge_stats[,1])
tsne_df <- as.data.frame(lapply(tsne_df, as.numeric)) #<- sapply is here
tsne_model_1 = Rtsne(tsne_df, check_duplicates=FALSE, pca=TRUE, perplexity=1, theta=0.5, dims=2)
d_tsne_1 = as.data.frame(tsne_model_1$Y)
## keeping original data
d_tsne_1_original <- d_tsne_1
Score_df <- matrix(nrow = 0, ncol = 1)
for(i in 1:(nrow(d_tsne_1) - 1)){
# create grid for parameter optimization
# generate clusters
fit_cluster_kmeans=kmeans(scale(d_tsne_1), i)
# calculate clusters
cluster_kmeans <- fit_cluster_kmeans$cluster
# add cluster to pos DF
dat <- cbind(d_tsne_1, cluster_kmeans)
if(max(cluster_kmeans) >  1){
s_score <- summary(silhouette(dat[,3], dist(dat[,1:2])))
Sil_ind <- mean(s_score$clus.avg.widths)
} else {
Sil_ind <- -1
}
Score_df <- rbind(Score_df, Sil_ind)
}
optimized_clus <- which.max(Score_df)
fit_cluster_kmeans=kmeans(scale(d_tsne_1), optimized_clus)
cluster_kmeans <- fit_cluster_kmeans$cluster
d_tsne_1_original$cl_kmeans = factor(fit_cluster_kmeans$cluster)
d_tsne_1_original$marker <- c('H&E', 'P16', 'P53', 'P63', 'uv-GATA3', 'Ki67', 'CK20', 'CK5-6', 'Her2Neu', 'Cyclin')
colnames(d_tsne_1_original) <- c('x', 'y', 'cluster', 'marker')
### create a copy
HE_part_stat <- Merge_stats
HE_part_stat[,2:11] <- as.data.frame(lapply(HE_part_stat[,2:11], as.numeric)) #<- sapply is here
colnames(HE_part_stat) <- c('TMA.core', 'H&E', 'P16', 'P53', 'P63', 'uv-GATA3', 'Ki67', 'CK20', 'CK5-6', 'Her2Neu', 'Cyclin')
View(fit_cluster_kmeans)
#------- boxplot all ------#
ratio <- max(Merge_stats_melt$value)/max(Merge_stats$QCoD)
ggplot() +
theme_bw(base_rect_size = 1) +
geom_boxplot(data = Merge_stats_melt, aes(x = reorder(TMA.core, value, FUN = function(x){(quantile(x, 0.75) - quantile(x, 0.25))/(quantile(x, 0.75) + quantile(x, 0.25))}), y = value), outlier.shape = NA) +
#geom_jitter(data = Merge_stats_melt, aes(x = reorder(TMA.core, value, FUN = function(x){sd(x)/mean(x)}), y = value),color = 'black', fill = 'white', shape=16, position=position_jitter(0.2)) +
#geom_point(data = Merge_stats_melt,aes(x = reorder(TMA.core, value, FUN = function(x){sd(x)/mean(x)}), y = value),color = 'black', size = 1) +
geom_dotplot(data = Merge_stats_melt,aes(x = reorder(TMA.core, value, FUN = function(x){(quantile(x, 0.75) - quantile(x, 0.25))/(quantile(x, 0.75) + quantile(x, 0.25))}), y = value),
binaxis = 'y', stackdir = 'center', dotsize = 0.2, color = 'black', fill = 'white') +
geom_line(data = Merge_stats, aes(x = reorder(TMA.core, QCoD), y = QCoD*ratio, group = 1), size =0.5, linetype = 1) +
geom_point(data = Merge_stats, aes(x = reorder(TMA.core, QCoD), y = QCoD*ratio, group = 1), size = 1) +
#geom_hline(yintercept = 0.1*ratio, linetype = 4) +
#geom_vline(xintercept = 118, linetype = 4) +
geom_point(data = Merge_stats, aes(x = reorder(TMA.core, QCoD), y = Mean, group = 1), color = 'red') +
#geom_point(aes(x = 118, y = 0.1*ratio), color = 'red', size = 1) +
scale_y_continuous(
name = expression(paste('Core area (')~ mm^{2}~ ')'),
sec.axis = sec_axis(~./ratio, name = 'Quartile Coeefficient of Dispersion')
) +
xlab('Core labels') +
theme(axis.text = element_text(angle = 90), axis.text.y = element_text(size = 10), axis.title = element_text(size = 15))
View(Merge_stats_melt)
View(Merge_stats)
#------- boxplot all ------#
write.csv(Merge_stats, 'Merge_stats')
#------- boxplot all ------#
write.csv(Merge_stats, 'Merge_stats.csv')
